{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3342, 50, 128)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.layers import LSTM, Dropout, Dense, BatchNormalization, Activation, Input, TimeDistributed\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU, PReLU\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from assignment.helpers import datapreparation as prep\n",
    "\n",
    "# Seed session\n",
    "np.random.seed(123456)\n",
    "rn.seed(123456)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=0,\n",
    "                              inter_op_parallelism_threads=0)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(123456)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "##\n",
    "\n",
    "fs1_dirpath = \"./assignment/datasets/training/piano_roll_fs1\"\n",
    "fs5_dirpath = \"./assignment/datasets/training/piano_roll_fs5\"\n",
    "\n",
    "\n",
    "# Load initial data\n",
    "datasets = prep.load_all_dataset(fs5_dirpath)\n",
    "dataset_names = prep.load_all_dataset_names(fs5_dirpath)\n",
    "unique_names = set()\n",
    "for name in dataset_names: # Make sure the same names get the same encoding each run\n",
    "    unique_names.add(name)\n",
    "unique_names = list(unique_names)\n",
    "name_to_int = dict([(unique_names[i], i) for i in range(len(unique_names))])\n",
    "int_to_name = dict([(i, unique_names[i]) for i in range(len(unique_names))])\n",
    "dataset_names = to_categorical([name_to_int[name] for name in dataset_names]) # one-hot encode the composers\n",
    "datasets = [dataset[:, 1:] for dataset in datasets] # Remove the headers\n",
    "\n",
    "# Setting initial parameters\n",
    "dataset_id_names = dict(zip(np.arange(len(dataset_names)), dataset_names))\n",
    "longest_song = max(datasets[i].shape[1] for i in range(len(datasets)))\n",
    "sequence_length = 50\n",
    "length = longest_song//sequence_length + 1\n",
    "num_keys = len(datasets[0])\n",
    "parts_per_song = int(longest_song/sequence_length)\n",
    "composer_encoding_len=len(dataset_names[0]) # 4 composers\n",
    "\n",
    "# Makes several datasets from this first one with differing intervals between to capture the \"gaps\" between two sequences\n",
    "# Add each subsequence of each song with differing offsets ([0:10], [1:11], [2:12], ...) to retain information.\n",
    "# Unable to implement stateful, so try to retain as much information between subsequences as possible. \n",
    "# Also a way of dataset augmentation (regularization) by increasing the size of the dataset\n",
    "\n",
    "def transpose_and_label_more(dataset_names, datasets, num_keys):\n",
    "    zs = []\n",
    "    datasets_transposed = np.array([(datasets[i].T, dataset_names[i]) for i in range(len(datasets))])\n",
    "    for song, composer in datasets_transposed:\n",
    "        for offset in range(0, sequence_length, 10): # Consider dropping offset, and use stateful to retain this info!\n",
    "            for i in range(0, len(song)//sequence_length-offset):\n",
    "                x = song[offset+i*sequence_length:offset+(i+1)*sequence_length]\n",
    "                if i == len(song)//sequence_length - (1 + offset): # Add the EOF marker if last seq of song\n",
    "                    y = np.append(song[offset+i*sequence_length+1:offset+(i+1)*sequence_length], np.array([np.ones(num_keys)]), 0)\n",
    "                else:\n",
    "                    y = song[offset+i*sequence_length+1:offset+(i+1)*sequence_length+1]\n",
    "                zs.append((x, y, composer))\n",
    "    xs, ys, composers = [], [], []\n",
    "    for x, y, composer in zs:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        composers.append(composer)\n",
    "    return np.array(xs), np.array(ys), np.array(composers)\n",
    "\n",
    "train_xs, train_ys, train_composers = transpose_and_label_more(dataset_names, datasets, num_keys)\n",
    "print(train_ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specialist_input = Input(shape=(composer_encoding_len,))\n",
    "x = Dense(32, activation=\"relu\")(specialist_input) # Change the activation function within as the sigmoid quickly saturates due to shape. It's ok as output though.\n",
    "specialist_output_h = Dense(num_keys, activation=\"relu\")(x)\n",
    "specialist_output_c = Dropout(0.2)(specialist_output_h)\n",
    "\n",
    "inputs = Input(shape=(sequence_length, num_keys))\n",
    "\n",
    "# Units = units per timestep LSTM block, i.e. output dimensionality (128 here since input and output 128 keys)\n",
    "lstm1 = LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True,\n",
    "               name=\"lstm1\")\n",
    "lstm1_outputs = lstm1(inputs, initial_state=[specialist_output_h, specialist_output_c]) # [h = prev output, c = memory], h should be None\n",
    "\n",
    "normalized1 = BatchNormalization()(lstm1_outputs)\n",
    "dense1 = Dense(num_keys*2, activation=\"relu\")(normalized1)\n",
    "dense1 = Dropout(0.3)(dense1)\n",
    "\n",
    "lstm2 = LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True)(dense1)\n",
    "\n",
    "normalized2 = BatchNormalization()(lstm2)\n",
    "outputs = TimeDistributed(Dense(num_keys, activation=\"sigmoid\",\n",
    "                               kernel_regularizer=l2(0.01),\n",
    "                               activity_regularizer=l1(0.01)))(normalized2) \n",
    "# Sigmoid keeps the probabilities independent of each other, while softmax does not!\n",
    "# kernel_regularizer = regulizer on weights\n",
    "# activity_regularizer = regularizer on outputs aka activations\n",
    "\n",
    "model = Model([inputs, specialist_input], outputs)\n",
    "\n",
    "adam = Adam(lr=0.001, amsgrad=True) \n",
    "# Ends up in a point where gradients really small, denominator really small and then loss exploding\n",
    "# v_t is based on the gradients at the current time step, and previous v_t, thus when gradient really small as well as v_t-1\n",
    "# the update denominator (sqrt(v_t) + epsilon) is so small that explodes.\n",
    "# AMSGrad maintains the maximum of all v_t until the present time step and uses this maximum value for normalizing\n",
    "# the running average of the gradient instead of the current v_t as is done in regular Adam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          4224        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 50, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 50, 128)      131584      input_2[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 128)      512         lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50, 256)      33024       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 256)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50, 128)      197120      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 128)      512         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 50, 128)      16512       batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 383,648\n",
      "Trainable params: 383,136\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(3342, 50, 128) (3342, 4) (3342, 50, 128)\n",
      "Epoch 1/500\n",
      "3342/3342 [==============================] - 24s 7ms/step - loss: 729.2291 - categorical_accuracy: 0.0070 0s - loss: 745.2409 - categorical_accura\n",
      "Epoch 2/500\n",
      "3342/3342 [==============================] - 25s 7ms/step - loss: 216.6639 - categorical_accuracy: 0.0111\n",
      "Epoch 3/500\n",
      "3342/3342 [==============================] - 27s 8ms/step - loss: 113.8934 - categorical_accuracy: 0.0127\n",
      "Epoch 4/500\n",
      "3342/3342 [==============================] - 22s 7ms/step - loss: 70.7228 - categorical_accuracy: 0.0130: 4s - loss: 74.6936 - catego\n",
      "Epoch 5/500\n",
      "3342/3342 [==============================] - 28s 8ms/step - loss: 32.4502 - categorical_accuracy: 0.0123\n",
      "Epoch 6/500\n",
      "3342/3342 [==============================] - 21s 6ms/step - loss: 13.4219 - categorical_accuracy: 0.0146\n",
      "Epoch 7/500\n",
      "3342/3342 [==============================] - 28s 8ms/step - loss: 10.1437 - categorical_accuracy: 0.0141\n",
      "Epoch 8/500\n",
      "3342/3342 [==============================] - 23s 7ms/step - loss: 9.4063 - categorical_accuracy: 0.0138\n",
      "Epoch 9/500\n",
      "3342/3342 [==============================] - 27s 8ms/step - loss: 9.0803 - categorical_accuracy: 0.0135\n",
      "Epoch 10/500\n",
      "3342/3342 [==============================] - 25s 7ms/step - loss: 8.7216 - categorical_accuracy: 0.0146\n",
      "Epoch 11/500\n",
      "3342/3342 [==============================] - 24s 7ms/step - loss: 8.4771 - categorical_accuracy: 0.0134\n",
      "Epoch 12/500\n",
      "3342/3342 [==============================] - 27s 8ms/step - loss: 8.1977 - categorical_accuracy: 0.0142\n",
      "Epoch 13/500\n",
      "3008/3342 [==========================>...] - ETA: 2s - loss: 8.0157 - categorical_accuracy: 0.0144 - ETA: 21s - loss: 8.0392 - categorical_acc - ETA: 16 - ETA: 7s -"
     ]
    }
   ],
   "source": [
    "# Want to penalize each output node independantly. \n",
    "# Log Loss aka multi-class multi-label as sigmoid -> binary CE, as want probs to be considered independent of each other.\n",
    "# Combo of sigmoid and crossentropy here log counteracts exp to reduce the saturation :)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # consider changing this one for others\n",
    "              metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(time()))\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=0, mode=\"auto\")\n",
    "\n",
    "print(train_xs.shape, train_composers.shape, train_ys.shape)\n",
    "model.fit([train_xs, train_composers], train_ys,\n",
    "          epochs=500, # Train harder more for more things was too bad train man :(\n",
    "          batch_size=32,\n",
    "          shuffle=True, # shuffle here but not when constructing set to be able to validate later on :)\n",
    "          #callbacks=[tensorboard],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict([train_xs, train_composers], verbose=True)\n",
    "maxes = [np.max(c) for c in a]\n",
    "plt.hist(maxes)\n",
    "plt.show()\n",
    "plt.hist(a[:,-1])\n",
    "plt.show()\n",
    "b = np.max(a[1][-1])\n",
    "plt.plot(a[1][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[0].T, fs=5)\n",
    "prep.visualize_piano_roll(train_xs[0].T, fs=5)\n",
    "plt.plot(a[100][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[100].T, fs=5)\n",
    "prep.visualize_piano_roll(train_xs[100].T, fs=5)\n",
    "plt.plot(a[200][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[200].T, fs=5)\n",
    "prep.visualize_piano_roll(train_xs[200].T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/nostate_50_offset_10_specialist_regularizer.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_song_from_predict(model, initial_data, composer, limit):\n",
    "    song = []\n",
    "    keep_producing = True\n",
    "    prev_data = initial_data\n",
    "    while keep_producing and len(song) < limit:\n",
    "        predictions = model.predict([np.array([prev_data]), composer])[0]\n",
    "        labels = np.zeros(predictions[-1].shape)\n",
    "        labels[predictions[-1]/np.max(predictions[-1])>0.75] = 1 # Threshold to consider the key as active, binarized based on this\n",
    "        last_output = labels\n",
    "        keep_producing = np.sum(last_output) != len(last_output)\n",
    "        song.append(last_output)\n",
    "        prev_data = np.append(prev_data[1:], [last_output], 0)\n",
    "    return np.array(song)\n",
    "\n",
    "initial_step = 543\n",
    "steps = 10\n",
    "song1 = make_song_from_predict(model, train_xs[initial_step], np.array([[1.0, 0.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song2 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 1.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song3 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 1.0, 0.0]]), sequence_length*steps)\n",
    "song4 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 0.0, 1.0]]), sequence_length*steps)\n",
    "prep.embed_play_v1(song1.T, fs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song2.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song3.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song4.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.visualize_piano_roll(song1.T, fs=5)\n",
    "prep.visualize_piano_roll(song2.T, fs=5)\n",
    "prep.visualize_piano_roll(song3.T, fs=5)\n",
    "prep.visualize_piano_roll(song4.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
