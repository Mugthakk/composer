{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 43, 10, 128)\n",
      "(84, 43, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.layers import LSTM, Dropout, Dense, BatchNormalization, Activation, Input, TimeDistributed, Masking\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU, PReLU\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "from assignment.helpers import datapreparation as prep\n",
    "\n",
    "\n",
    "# Can make the midi actually play by multiply the notes (0-128, so 1 is basically silence).\n",
    "\n",
    "# Note on specifying the initial state of RNNs\n",
    "# Seems as though you can reset state (probably stateful=True), and then pass an array of initial states that can be used\n",
    "# in the RNN - so initialize based on composer :D\n",
    "# https://keras.io/layers/recurrent/\n",
    "\n",
    "fs1_dirpath = \"./assignment/datasets/training/piano_roll_fs1\"\n",
    "\n",
    "datasets = prep.load_all_dataset(fs1_dirpath)\n",
    "dataset_names = prep.load_all_dataset_names(fs1_dirpath)\n",
    "\n",
    "datasets = [dataset[:, 1:] for dataset in datasets] # Remove the headers\n",
    "\n",
    "dataset_id_names = dict(zip(np.arange(len(dataset_names)), dataset_names))\n",
    "longest_song = max(datasets[i].shape[1] for i in range(len(datasets)))\n",
    "sequence_length = 10\n",
    "num_batches = longest_song//sequence_length + 1\n",
    "num_keys = len(datasets[0])\n",
    "pad_length = num_batches*sequence_length\n",
    "num_songs = len(datasets)\n",
    "b_size = 21 # feed one and one to control reset states for stateful, hella slow though :(\n",
    "\n",
    "def preprocess_for_stateful_with_padding(dataset, num_songs, sequence_length, num_batches, num_keys, pad_length):\n",
    "    big_af = [[[] for a in range(num_songs)] for b in range(num_batches)]\n",
    "    songs_padded = pad_sequences(dataset, maxlen=pad_length, padding=\"post\", value=np.array([-1.0 for _ in range(num_keys)]))\n",
    "    for i in range(num_batches):\n",
    "        for j in range(num_songs):\n",
    "            big_af[i][j] = songs_padded[j, i*sequence_length:(i+1)*sequence_length]\n",
    "    return np.array(big_af)\n",
    "\n",
    "def preprocess_for_3d(dataset, num_songs, sequence_length, num_batches, num_keys, pad_length):\n",
    "    big_af = [[] for song in dataset]\n",
    "    songs_padded = pad_sequences(dataset, maxlen=pad_length, padding=\"post\", value=np.array([-1.0 for _ in range(num_keys)]))\n",
    "    for i in range(num_songs):\n",
    "        for j in range(num_batches):\n",
    "            big_af[i].append([songs_padded[i,j*sequence_length:(j+1)*sequence_length]])\n",
    "    return np.array(big_af)\n",
    "\n",
    "datasets = np.array([dataset.T for dataset in datasets])\n",
    "xs = preprocess_for_stateful_with_padding(datasets, num_songs, sequence_length, num_batches, num_keys, pad_length)\n",
    "datasets_labels = np.array([np.append(dataset[1:,:], np.array([np.ones(num_keys)]), axis=0) for dataset in datasets])\n",
    "ys = preprocess_for_stateful_with_padding(datasets_labels, num_songs, sequence_length, num_batches, num_keys, pad_length)\n",
    "print(xs.shape)\n",
    "print(ys.shape)\n",
    "# 84 batches x 43 songs x 10 time_steps x 128 piano_keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(batch_shape=(b_size, num_songs, sequence_length, num_keys))\n",
    "mask = TimeDistributed(Masking(mask_value=-1.0))(inputs)\n",
    "# Units = units per timestep LSTM block, i.e. output dimensionality (128 here since input and output 128 keys)\n",
    "lstm1 = TimeDistributed(LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True,\n",
    "               stateful=True,\n",
    "               dropout=0.0, #0.2, #0.25,\n",
    "               recurrent_dropout=0.0, #0.25,\n",
    "               kernel_regularizer=None,#l2(0.0001),\n",
    "               recurrent_regularizer=None, #l2(0.0001),\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,#l2(0.0001),\n",
    "               ))(inputs)\n",
    "normalized1 = TimeDistributed(BatchNormalization())(lstm1)\n",
    "dense1 = TimeDistributed(Dense(num_keys, activation=\"sigmoid\"))(normalized1)\n",
    "lstm2 = TimeDistributed(LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True,\n",
    "               stateful=True,\n",
    "               dropout=0.0, #0.2, #0.25,\n",
    "               recurrent_dropout=0.0, #0.25,\n",
    "               kernel_regularizer=None,#l2(0.0001),\n",
    "               recurrent_regularizer=None, #l2(0.0001),\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,#l2(0.0001),\n",
    "               ))(dense1)\n",
    "normalized2 = TimeDistributed(BatchNormalization())(lstm2)\n",
    "dense2 = TimeDistributed(TimeDistributed(Dense(num_keys, activation=\"sigmoid\")))(normalized2)\n",
    "outputs = TimeDistributed(Dense(num_keys, activation=\"sigmoid\"))(normalized2) # Sigmoid keeps the probabilities independent of each other, while softmax does not!\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "rmsprop = RMSprop(lr=0.001)\n",
    "adagrad =  Adagrad(lr=0.001)\n",
    "adam = Adam(lr=0.001, amsgrad=True) #Ends up in a point where gradients really small, denominator really small and then loss exploding\n",
    "adadelta = Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Want to penalize each output node independantly. So we pick a binary loss \n",
    "# and model the output of the network as a independent bernoulli distributions per label.\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # consider changing this one for others\n",
    "              metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(time()))\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=0, mode=\"auto\")\n",
    "\n",
    "\n",
    "model.fit(xs, ys, batch_size=b_size, epochs=50, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model.predict(xs, verbose=True, batch_size=b_size)\n",
    "print(model.layers)\n",
    "#print(model.layers[1].states[0])\n",
    "#print(model.layers[1].states[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix these\n",
    "maxes = [np.max(c) for c in a]\n",
    "plt.hist(maxes)\n",
    "plt.show()\n",
    "plt.hist(a[:,:,-1])\n",
    "plt.show()\n",
    "b = np.max(a[1][-1])\n",
    "plt.plot(a[0][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[0][0].T, fs=1)\n",
    "prep.visualize_piano_roll(xs[0][0].T, fs=1)\n",
    "plt.plot(a[100][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[1][0].T, fs=1)\n",
    "prep.visualize_piano_roll(xs[1][0].T, fs=1)\n",
    "plt.plot(a[200][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[2][0].T, fs=1)\n",
    "prep.visualize_piano_roll(xs[2][0].T, fs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_song_from_predict(model, initial_data, limit):\n",
    "    song = []\n",
    "    keep_producing = True\n",
    "    prev_data = initial_data\n",
    "    while keep_producing and len(song) < limit:\n",
    "        #print(\"input\", prev_data)\n",
    "        predictions = model.predict(np.array([prev_data]))[0]\n",
    "        #print(\"output\", predictions[-1])\n",
    "        #plt.plot(predictions[-1])\n",
    "        #plt.show()\n",
    "        labels = np.zeros(predictions.shape)\n",
    "        labels[predictions>0.5] = 1 # Weak activations, want to scale to 0/1\n",
    "        last_output = labels[-1]\n",
    "        #print(\"output scaled:\", last_output)\n",
    "        keep_producing = np.sum(last_output) != len(last_output)\n",
    "        song.append(last_output)\n",
    "        prev_data = np.append(prev_data[1:], [last_output], 0)\n",
    "    return np.array(song)\n",
    "\n",
    "initial_step = 1250\n",
    "song = make_song_from_predict(model, test_xs[initial_step], sequence_length)\n",
    "prep.visualize_piano_roll(song.T, fs=1)\n",
    "prep.visualize_piano_roll(test_xs[initial_step].T, fs=1)\n",
    "prep.embed_play_v1(song.T, fs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep.visualize_piano_roll(test_xs[initial_step+1].T, fs=1)\n",
    "prep.embed_play_v1(test_xs[initial_step+1].T, fs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
