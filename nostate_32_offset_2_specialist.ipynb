{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.layers import LSTM, Dropout, Dense, BatchNormalization, Activation, Input, TimeDistributed\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU, PReLU\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from assignment.helpers import datapreparation as prep\n",
    "\n",
    "\n",
    "\n",
    "fs1_dirpath = \"./assignment/datasets/training/piano_roll_fs1\"\n",
    "fs2_dirpath = \"./assignment/datasets/training/piano_roll_fs2\"\n",
    "fs5_dirpath = \"./assignment/datasets/training/piano_roll_fs5\"\n",
    "\n",
    "\n",
    "# Load initial data\n",
    "datasets = prep.load_all_dataset(fs2_dirpath)\n",
    "dataset_names = prep.load_all_dataset_names(fs2_dirpath)\n",
    "unique_names = set()\n",
    "for name in dataset_names: # Make sure the same names get the same encoding each run\n",
    "    unique_names.add(name)\n",
    "unique_names = list(unique_names)\n",
    "name_to_int = dict([(unique_names[i], i) for i in range(len(unique_names))])\n",
    "int_to_name = dict([(i, unique_names[i]) for i in range(len(unique_names))])\n",
    "dataset_names = to_categorical([name_to_int[name] for name in dataset_names]) # one-hot encode the composers\n",
    "datasets = [dataset[:, 1:] for dataset in datasets] # Remove the headers\n",
    "\n",
    "# Setting initial parameters\n",
    "dataset_id_names = dict(zip(np.arange(len(dataset_names)), dataset_names))\n",
    "longest_song = max(datasets[i].shape[1] for i in range(len(datasets)))\n",
    "sequence_length = 32\n",
    "length = longest_song//sequence_length + 1\n",
    "num_keys = len(datasets[0])\n",
    "parts_per_song = int(longest_song/sequence_length)\n",
    "composer_encoding_len=len(dataset_names[0]) # 4 composers\n",
    "\n",
    "# Makes several datasets from this first one with differing intervals between to capture the \"gaps\" between two sequences\n",
    "# Add each subsequence of each song with differing offsets ([0:10], [1:11], [2:12], ...) to retain information.\n",
    "# Unable to implement stateful, so try to retain as much information between subsequences as possible. \n",
    "# Also a way of dataset augmentation (regularization) by increasing the size of the dataset\n",
    "\n",
    "def transpose_and_label_more(dataset_names, datasets, num_keys):\n",
    "    zs = []\n",
    "    datasets_transposed = np.array([(datasets[i].T, dataset_names[i]) for i in range(len(datasets))])\n",
    "    for song, composer in datasets_transposed:\n",
    "        for offset in range(0, sequence_length, 2):\n",
    "            for i in range(0, len(song)//sequence_length-offset):\n",
    "                x = song[offset+i*sequence_length:offset+(i+1)*sequence_length]\n",
    "                if i == len(song)//sequence_length - (1+offset): # Add the EOF marker if last seq of song\n",
    "                    y = np.append(song[offset+i*sequence_length+1:offset+(i+1)*sequence_length], np.array([np.ones(num_keys)]), 0)\n",
    "                else:\n",
    "                    y = song[offset+i*sequence_length+1:offset+(i+1)*sequence_length+1]\n",
    "                zs.append((x, y, composer))\n",
    "    np.random.shuffle(zs)\n",
    "    xs, ys, composers = [], [], []\n",
    "    for x, y, composer in zs:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        composers.append(composer)\n",
    "    return np.array(xs), np.array(ys), np.array(composers)\n",
    "\n",
    "train_xs, train_ys, train_composers = transpose_and_label_more(dataset_names, datasets, num_keys)\n",
    "test_xs = train_xs[int(len(train_xs)*0.8):]\n",
    "train_xs = train_xs[:int(len(train_xs)*0.8)]\n",
    "test_ys = train_ys[int(len(train_ys)*0.8):]\n",
    "train_ys = train_ys[:int(len(train_ys)*0.8)]\n",
    "test_composers = train_composers[int(len(train_composers)*0.8):]\n",
    "train_composers = train_composers[:int(len(train_composers)*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specialist_input = Input(shape=(composer_encoding_len,))\n",
    "x = Dense(64, activation=\"relu\")(specialist_input) # Change the activation function within as the sigmoid quickly saturates due to shape. It's ok as output though.\n",
    "specialist_output_c = Dense(num_keys, activation=\"relu\")(x)\n",
    "#specialist_output_h = Dense(num_keys, activation=\"relu\")(x)\n",
    "specialist_output_h = Dropout(0.2)(specialist_output_c) # Hax to privde 0 as initial h.\n",
    "\n",
    "inputs = Input(shape=(sequence_length, num_keys))\n",
    "\n",
    "# Units = units per timestep LSTM block, i.e. output dimensionality (128 here since input and output 128 keys)\n",
    "lstm1 = LSTM(num_keys,\n",
    "               return_sequences=True,\n",
    "               activation=\"relu\",\n",
    "               name=\"lstm1\")\n",
    "lstm1_outputs = lstm1(inputs, initial_state=[specialist_output_h, specialist_output_c]) # [h = prev output, c = memory], h should be None\n",
    "\n",
    "normalized1 = BatchNormalization()(lstm1_outputs)\n",
    "dense1 = Dense(num_keys, activation=\"relu\")(normalized1)\n",
    "\n",
    "lstm2 = LSTM(num_keys,\n",
    "               return_sequences=True)(dense1)\n",
    "\n",
    "normalized2 = BatchNormalization()(lstm2)\n",
    "dense2 = Dense(num_keys, activation=\"relu\")(normalized2)\n",
    "\n",
    "lstm3 = LSTM(num_keys, activation=\"relu\", return_sequences=True)(dense2)\n",
    "normalized3 = BatchNormalization()(lstm3)\n",
    "\n",
    "outputs = TimeDistributed(Dense(num_keys, activation=\"sigmoid\"))(normalized3) # Sigmoid keeps the probabilities independent of each other, while softmax does not!\n",
    "\n",
    "model = Model([inputs, specialist_input], outputs)\n",
    "\n",
    "adam = Adam(lr=0.001, amsgrad=True) \n",
    "# Ends up in a point where gradients really small, denominator really small and then loss exploding\n",
    "# v_t is based on the gradients at the current time step, and previous v_t, thus when gradient really small as well as v_t-1\n",
    "# the update denominator (sqrt(v_t) + epsilon) is so small that explodes.\n",
    "# AMSGrad maintains the maximum of all v_t until the present time step and uses this maximum value for normalizing\n",
    "# the running average of the gradient instead of the current v_t as is done in regular Adam.\n",
    "\n",
    "#model.save(\"./models/latest.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 32, 128)      131584      input_2[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 128)      512         lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32, 128)      16512       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32, 128)      131584      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 128)      512         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32, 128)      16512       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32, 128)      131584      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 128)      512         lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 32, 128)      16512       batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 454,464\n",
      "Trainable params: 453,696\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(4421, 32, 128) (4421, 4) (4421, 32, 128)\n",
      "Train on 4421 samples, validate on 1106 samples\n",
      "Epoch 1/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.4682 - categorical_accuracy: 0.0314 - val_loss: 0.1760 - val_categorical_accuracy: 0.0515\n",
      "Epoch 2/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.1002 - categorical_accuracy: 0.0714 - val_loss: 0.0905 - val_categorical_accuracy: 0.0694\n",
      "Epoch 3/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0850 - categorical_accuracy: 0.0790 - val_loss: 0.1070 - val_categorical_accuracy: 0.0763 categorical_ac - ETA: 14s - loss: 0.0859 - categorical_accuracy: 0.07 - ETA: 14s - loss: 0.0860 - categorical_\n",
      "Epoch 4/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0811 - categorical_accuracy: 0.0880 - val_loss: 0.0807 - val_categorical_accuracy: 0.0927\n",
      "Epoch 5/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0786 - categorical_accuracy: 0.0971 - val_loss: 0.0788 - val_categorical_accuracy: 0.1024cal_a - ETA: 9s - loss: 0.0785 - categorical_ - ETA: 8s - ETA: 3s - l\n",
      "Epoch 6/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0762 - categorical_accuracy: 0.1063 - val_loss: 0.0766 - val_categorical_accuracy: 0.1082\n",
      "Epoch 7/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0742 - categorical_accuracy: 0.1105 - val_loss: 0.0757 - val_categorical_accuracy: 0.1143s - loss: 0.0740 -  - ETA: 3s - loss: 0.0\n",
      "Epoch 8/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0722 - categorical_accuracy: 0.1159 - val_loss: 0.0743 - val_categorical_accuracy: 0.1093TA: 4s - loss: 0.072 - ETA: 1s - loss: 0.0722 - categorical_\n",
      "Epoch 9/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0705 - categorical_accuracy: 0.1198 - val_loss: 0.0747 - val_categorical_accuracy: 0.1153\n",
      "Epoch 10/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0690 - categorical_accuracy: 0.1233 - val_loss: 0.0737 - val_categorical_accuracy: 0.1223\n",
      "Epoch 11/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0677 - categorical_accuracy: 0.1273 - val_loss: 0.0734 - val_categorical_accuracy: 0.1306\n",
      "Epoch 12/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0663 - categorical_accuracy: 0.1312 - val_loss: 0.0763 - val_categorical_accuracy: 0.1250orical_accura - ETA: 14s - los - ETA: 2s - loss: 0.0662 - categorical_accura - ETA: 1s - loss: 0.0662 - categori\n",
      "Epoch 13/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0658 - categorical_accuracy: 0.1350 - val_loss: 0.0736 - val_categorical_accuracy: 0.1318\n",
      "Epoch 14/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0643 - categorical_accuracy: 0.1384 - val_loss: 0.0714 - val_categorical_accuracy: 0.1350\n",
      "Epoch 15/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0630 - categorical_accuracy: 0.1413 - val_loss: 0.0719 - val_categorical_accuracy: 0.1321\n",
      "Epoch 16/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0621 - categorical_accuracy: 0.1475 - val_loss: 0.0718 - val_categorical_accuracy: 0.136821 \n",
      "Epoch 17/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0603 - categorical_accuracy: 0.1525 - val_loss: 0.0716 - val_categorical_accuracy: 0.1401\n",
      "Epoch 18/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0594 - categorical_accuracy: 0.1546 - val_loss: 0.0703 - val_categorical_accuracy: 0.1445\n",
      "Epoch 19/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0590 - categorical_accuracy: 0.1600 - val_loss: 0.0705 - val_categorical_accuracy: 0.1513\n",
      "Epoch 20/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0580 - categorical_accuracy: 0.1617 - val_loss: 0.0697 - val_categorical_accuracy: 0.1698580 - categorical_ac\n",
      "Epoch 21/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0579 - categorical_accuracy: 0.1653 - val_loss: 0.0695 - val_categorical_accuracy: 0.1541\n",
      "Epoch 22/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0562 - categorical_accuracy: 0.1693 - val_loss: 0.0695 - val_categorical_accuracy: 0.1672\n",
      "Epoch 23/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0553 - categorical_accuracy: 0.1771 - val_loss: 0.0701 - val_categorical_accuracy: 0.1712 0.0566 - categorical_a - ETA: 15s - loss: 0.0562 - cat - ETA: 1 - ETA: 5s - loss: 0.0557 - categori - ETA: 3s - l\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0547 - categorical_accuracy: 0.1800 - val_loss: 0.0680 - val_categorical_accuracy: 0.1675\n",
      "Epoch 25/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0536 - categorical_accuracy: 0.1831 - val_loss: 0.0669 - val_categorical_accuracy: 0.1766\n",
      "Epoch 26/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0532 - categorical_accuracy: 0.1848 - val_loss: 0.0676 - val_categorical_accuracy: 0.1770uracy: \n",
      "Epoch 27/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0525 - categorical_accuracy: 0.1889 - val_loss: 0.0664 - val_categorical_accuracy: 0.1793\n",
      "Epoch 28/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0513 - categorical_accuracy: 0.1952 - val_loss: 0.0661 - val_categorical_accuracy: 0.1876TA: 23s - loss: 0.0525 - categorical_ - ETA: 20s - loss: 0.0521 - categori - ETA: 16s - loss: 0.0517 - categorical_accuracy - ETA: 14s - loss: 0.0517 - categorical_accuracy - ETA: 13s - loss: 0.0514 - categorical_accura - ETA: 11s - loss: 0.0512 - categorical_a - ETA: 9s - loss: 0.0513 -  - ETA: 1s - loss: 0.0512 - categorical_ac\n",
      "Epoch 29/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0509 - categorical_accuracy: 0.1950 - val_loss: 0.0646 - val_categorical_accuracy: 0.19540.0512 - categorical_accuracy: 0. - ETA: 13s - loss: 0.0511  - ETA: 8s - loss: 0.0510 - categorical_accu - ETA: 6s - loss: 0.0510 - categorical_ - ETA: 5s - loss: 0.0510 - categori - ETA: 3s - loss: 0.0509 \n",
      "Epoch 30/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0491 - categorical_accuracy: 0.2045 - val_loss: 0.0645 - val_categorical_accuracy: 0.1991 loss:\n",
      "Epoch 31/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0489 - categorical_accuracy: 0.2064 - val_loss: 0.0652 - val_categorical_accuracy: 0.185322s - loss: 0.0477 - categorical_accura - ETA: 20s - loss: 0.0481 - categorical_accuracy: 0.20 - ETA: 20s - loss: 0.0484 - categorical_accuracy: 0.208 - ETA: 20s - loss:\n",
      "Epoch 32/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0487 - categorical_accuracy: 0.2107 - val_loss: 0.0633 - val_categorical_accuracy: 0.2080tegorical_accur - ETA: 16s - loss: 0.0483 - categorical_accuracy: - ETA: 15s - loss: 0.0484 - categorical_accuracy: 0.2 - ETA: 14s - loss: 0.0484 - categorical_accuracy - ETA: 13s - l - ETA: 7s - loss: 0.0488 - cate\n",
      "Epoch 33/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0483 - categorical_accuracy: 0.2108 - val_loss: 0.0632 - val_categorical_accuracy: 0.2048ss: 0.0491 - categorical_accuracy:  - ETA: 21s - loss: 0.0 - ETA: 12s  - ETA: 6s - - ETA: 1s - loss: 0.0485 - categori\n",
      "Epoch 34/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0468 - categorical_accuracy: 0.2182 - val_loss: 0.0625 - val_categorical_accuracy: 0.2112loss: 0.0468 - categorical_accura - ETA: 2s - loss: 0.0468 - ca\n",
      "Epoch 35/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0463 - categorical_accuracy: 0.2201 - val_loss: 0.0620 - val_categorical_accuracy: 0.2135 categorical_accuracy: 0. - ETA: 19s - loss: 0.0454 - c - ETA: 0s - loss: 0.0464 - categorical_accuracy\n",
      "Epoch 36/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0448 - categorical_accuracy: 0.2255 - val_loss: 0.0625 - val_categorical_accuracy: 0.2149\n",
      "Epoch 37/500\n",
      "4421/4421 [==============================] - 33s 8ms/step - loss: 0.0445 - categorical_accuracy: 0.2286 - val_loss: 0.0614 - val_categorical_accuracy: 0.2242cu - ETA:  - ETA: 1s - loss: 0.0445 - categorica\n",
      "Epoch 38/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0439 - categorical_accuracy: 0.2308 - val_loss: 0.0605 - val_categorical_accuracy: 0.2212ETA: 7s - loss: 0.0439 - categorical_ac - ETA: 5s - loss: 0.0439 - categorical_accuracy: 0. - ETA: 4s - loss: 0.0438 - categorical_accu - ETA: 3s - loss: 0.0439 - categorical_accuracy: 0. - ETA: 3s - loss: 0.0439 - \n",
      "Epoch 39/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0433 - categorical_accuracy: 0.2365 - val_loss: 0.0599 - val_categorical_accuracy: 0.2312 loss: 0.0428 - categorical_accuracy: 0.23 - ETA: 18s - loss: 0.0428 - categorical_accuracy: 0.238 - ETA: 18s - loss: 0.0428 - categorical_accuracy:  - ETA: 17s - loss: 0.0428 \n",
      "Epoch 40/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0426 - categorical_accuracy: 0.2411 - val_loss: 0.0613 - val_categorical_accuracy: 0.22028s - loss: 0.0422 -  - ETA: 5s - - ETA: 1s - loss: 0.0425 - categorical_ac\n",
      "Epoch 41/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0424 - categorical_accuracy: 0.2415 - val_loss: 0.0599 - val_categorical_accuracy: 0.238326 \n",
      "Epoch 42/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0417 - categorical_accuracy: 0.2475 - val_loss: 0.0604 - val_categorical_accuracy: 0.231419s - loss: - ETA: 5s - loss: 0.0414 - categorical_accuracy: 0. - ETA: 5s - loss: 0.0 - ETA: 1s - loss: 0.0416 - categorical_accuracy - ETA: 0s - loss: 0.0417 - categorical_accuracy: 0.24 - ETA: 0s - loss: 0.0417 - categorical_accuracy: 0.24\n",
      "Epoch 43/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0410 - categorical_accuracy: 0.2504 - val_loss: 0.0600 - val_categorical_accuracy: 0.2347\n",
      "Epoch 44/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0408 - categorical_accuracy: 0.2506 - val_loss: 0.0592 - val_categorical_accuracy: 0.2479.0409 - catego - ETA: 0s - loss: 0.0408 - categorical_accuracy: 0.25\n",
      "Epoch 45/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0396 - categorical_accuracy: 0.2592 - val_loss: 0.0599 - val_categorical_accuracy: 0.2532 loss: 0.0396 - categorical_accuracy: 0 - ETA: 12s - loss: 0.0395 - categorical_accura - ETA: 9s - loss: 0.0395 - ca - ETA: 6s - loss: 0.0396 - cate - ETA: 3s - loss: 0.0396 - categorical_accuracy - ETA: 2s - loss: 0.0396 - categorical_ - ETA: 0s - loss: 0.0396 - categorical_accuracy: 0.25 - ETA: 0s - loss: 0.0396 - categorical_accuracy: 0.\n",
      "Epoch 46/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0392 - categorical_accuracy: 0.2605 - val_loss: 0.0569 - val_categorical_accuracy: 0.2496uracy:  - ETA: 0s - loss: 0.0392 - categorical_accuracy: 0.26\n",
      "Epoch 47/500\n",
      "4421/4421 [==============================] - 33s 8ms/step - loss: 0.0382 - categorical_accuracy: 0.2650 - val_loss: 0.0580 - val_categorical_accuracy: 0.25120382 - categorical_ac - ETA: 13s - loss: 0.0381 - categorical_accur\n",
      "Epoch 48/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0383 - categorical_accuracy: 0.2641 - val_loss: 0.0586 - val_categorical_accuracy: 0.2561ETA: 30s - loss: 0.038 - ETA: 18s - loss: 0.0388  - ETA: 11s - loss: 0.0385 - categorical_accuracy: 0 - ETA: 10s - loss: 0.0385 - categorical_ - ETA: 2s - loss: 0.0382 - categorical_accuracy:  - ETA: 1s - loss: 0.0382 - categori\n",
      "Epoch 49/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0381 - categorical_accuracy: 0.2689 - val_loss: 0.0576 - val_categorical_accuracy: 0.2540\n",
      "Epoch 50/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0387 - categorical_accuracy: 0.2648 - val_loss: 0.0585 - val_categorical_accuracy: 0.2515\n",
      "Epoch 51/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0390 - categorical_accuracy: 0.2644 - val_loss: 0.0585 - val_categorical_accuracy: 0.2634ical_accuracy: - ETA: 17s - loss: 0.0405 - categorical_acc - ETA: 14s - loss: 0.0400 - categorical_accuracy: 0. - ETA: 14s - loss: 0.0399 - categorical_accuracy:  - ETA: 13s - loss: 0.039 - ETA: 3s - loss: 0.0\n",
      "Epoch 52/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0374 - categorical_accuracy: 0.2755 - val_loss: 0.0564 - val_categorical_accuracy: 0.26481s - loss: 0.0382 - catego - ETA: 15s - loss: 0.0377 - categorical_accuracy: 0 - ETA: 13s -  - ETA: 6s - loss: 0.0377  - ETA: 3s - loss: 0.037\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0353 - categorical_accuracy: 0.2828 - val_loss: 0.0556 - val_categorical_accuracy: 0.2824\n",
      "Epoch 54/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0356 - categorical_accuracy: 0.2841 - val_loss: 0.0571 - val_categorical_accuracy: 0.2646\n",
      "Epoch 55/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0355 - categorical_accuracy: 0.2838 - val_loss: 0.0560 - val_categorical_accuracy: 0.2735categorical_accu - ETA: 15s - loss: 0.0366 - categorical_accuracy: 0. - ETA: 14s - loss: 0.0365 - categorical_ac - ETA: 12s - loss: 0.0361 - categorical_accuracy: 0. - ETA: 11s - loss: 0.0359 - categorical_accurac - ETA: 9s - loss: 0.0358 - categorical_accu - ETA: 8s - loss: 0\n",
      "Epoch 56/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0340 - categorical_accuracy: 0.2907 - val_loss: 0.0557 - val_categorical_accuracy: 0.27422s - loss: 0.0341 - categorical_accura - ETA: 0s - loss: 0.0341 - categorical_accura\n",
      "Epoch 57/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0342 - categorical_accuracy: 0.2910 - val_loss: 0.0537 - val_categorical_accuracy: 0.2894A: 22s - loss: 0.0349 - categorical_accuracy: 0. - ETA: 2 - ETA: 6s - ETA: 0s - loss: 0.0342 - categorical_accuracy: \n",
      "Epoch 58/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0337 - categorical_accuracy: 0.2959 - val_loss: 0.0547 - val_categorical_accuracy: 0.2729\n",
      "Epoch 59/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0339 - categorical_accuracy: 0.2932 - val_loss: 0.0566 - val_categorical_accuracy: 0.2758- loss: 0.0344 - categorical_accuracy - ETA: 20s - loss: 0.0339 - categorical_accuracy: 0 - ETA: 19s - loss: 0.0338 - categorical_accuracy: 0 - ETA: 18s - loss: 0.0340 - categorical_accuracy: - ETA: 16s - loss: 0.0338 - categorical_accurac - ETA: 15s - loss: 0.0338 - categorical_accuracy: 0.29 - ETA: 14s - loss: 0.0338 - categorical_accuracy: 0. - ETA: 13s - loss: 0.0337 - categorical_accurac - ETA: 12s - loss: 0.0337 - categorical_accuracy: - ETA: 10s - loss: 0.0339 - categorical_accuracy: 0.296 - ETA: 10s - loss: 0.0339 - categorical_accuracy: 0.2 - ETA:  - ETA: 5s - loss: 0.0339 - categorical_accuracy - ETA\n",
      "Epoch 60/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0335 - categorical_accuracy: 0.2979 - val_loss: 0.0544 - val_categorical_accuracy: 0.2963tegorical_accur - ETA: 9s - loss: 0.0336 - categorical_ac - ETA - ETA: 1s - loss: 0.0335 - categorica\n",
      "Epoch 61/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0328 - categorical_accuracy: 0.2989 - val_loss: 0.0550 - val_categorical_accuracy: 0.287520s - loss: 0\n",
      "Epoch 62/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0321 - categorical_accuracy: 0.3032 - val_loss: 0.0539 - val_categorical_accuracy: 0.3003\n",
      "Epoch 63/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0313 - categorical_accuracy: 0.3085 - val_loss: 0.0524 - val_categorical_accuracy: 0.3075\n",
      "Epoch 64/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0314 - categorical_accuracy: 0.3092 - val_loss: 0.0525 - val_categorical_accuracy: 0.3104 17s -  - ETA: 7s - loss: 0.0314 - categorica - ETA: 5s - loss: 0.0315 - categorical_accura - ETA: 3s - loss: 0.0\n",
      "Epoch 65/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0299 - categorical_accuracy: 0.3173 - val_loss: 0.0523 - val_categorical_accuracy: 0.3070\n",
      "Epoch 66/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0299 - categorical_accuracy: 0.3156 - val_loss: 0.0526 - val_categorical_accuracy: 0.3143\n",
      "Epoch 67/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0295 - categorical_accuracy: 0.3187 - val_loss: 0.0509 - val_categorical_accuracy: 0.3074s - loss: 0.0297 - categorical_accuracy: 0.316 - ETA: 21s - loss: 0.0297 - categorical_accuracy - ETA: 19s - loss: 0.0295 - catego - E\n",
      "Epoch 68/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0293 - categorical_accuracy: 0.3204 - val_loss: 0.0546 - val_categorical_accuracy: 0.2930\n",
      "Epoch 69/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0290 - categorical_accuracy: 0.3188 - val_loss: 0.0517 - val_categorical_accuracy: 0.3169\n",
      "Epoch 70/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0284 - categorical_accuracy: 0.3227 - val_loss: 0.0523 - val_categorical_accuracy: 0.3221\n",
      "Epoch 71/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0279 - categorical_accuracy: 0.3254 - val_loss: 0.0516 - val_categorical_accuracy: 0.3278 los - ETA: 10s - loss: 0.0275 - categorical_accuracy: - ETA: 9s - loss: 0.0276 - catego - ETA: 6s - loss: 0.0276 - categorical_accuracy: 0.32 - ETA: 6s - loss: 0.0276 - categorical_accuracy:  - ETA: 5s - ETA: 0s - loss: 0.0279 - categorical_accuracy: 0.32\n",
      "Epoch 72/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0286 - categorical_accuracy: 0.3259 - val_loss: 0.0525 - val_categorical_accuracy: 0.3233\n",
      "Epoch 73/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0359 - categorical_accuracy: 0.2967 - val_loss: 0.0623 - val_categorical_accuracy: 0.2673\n",
      "Epoch 74/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0335 - categorical_accuracy: 0.3042 - val_loss: 0.0548 - val_categorical_accuracy: 0.2926 - loss: 0.0375 - categorical_accur - ETA\n",
      "Epoch 75/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0296 - categorical_accuracy: 0.3217 - val_loss: 0.0512 - val_categorical_accuracy: 0.3126ETA: 10s - loss: - ETA: 5s - loss: 0.0298 - categori - ETA: 3s - loss: 0.0 - ETA: 0s - loss: 0.0296 - categorical_accuracy: 0.\n",
      "Epoch 76/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0280 - categorical_accuracy: 0.3289 - val_loss: 0.0500 - val_categorical_accuracy: 0.3298oss: 0.0282 - categorical_accu - ETA: 8s - loss: 0.0282 - categorical_ - ETA: 5s - loss: 0.0282 - categorical_accuracy - ETA: 4s - loss: 0.0281 - categorical_accuracy: 0. - ETA: 4s - loss: 0.0281 - categorical_accura - ETA: 3s - loss: 0.0281 - \n",
      "Epoch 77/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0266 - categorical_accuracy: 0.3369 - val_loss: 0.0488 - val_categorical_accuracy: 0.3337\n",
      "Epoch 78/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0259 - categorical_accuracy: 0.3387 - val_loss: 0.0508 - val_categorical_accuracy: 0.3264  - ETA: 13s - loss: 0.0257 - categorical_accuracy: 0.343 - ETA: 13s - loss: 0.0257 - categoric - ETA:\n",
      "Epoch 79/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0266 - categorical_accuracy: 0.3377 - val_loss: 0.0486 - val_categorical_accuracy: 0.3358\n",
      "Epoch 80/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0260 - categorical_accuracy: 0.3396 - val_loss: 0.0508 - val_categorical_accuracy: 0.3330\n",
      "Epoch 81/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0260 - categorical_accuracy: 0.3395 - val_loss: 0.0501 - val_categorical_accuracy: 0.3201\n",
      "Epoch 82/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0255 - categorical_accuracy: 0.3408 - val_loss: 0.0485 - val_categorical_accuracy: 0.3469y: - ETA: 14s - loss: 0.0253 - categorical_accur - ETA: 12s - loss: 0.0254 - categorical_accurac - ETA: 10s - loss: 0.0256 - categorical_accuracy: 0 - ETA: \n",
      "Epoch 83/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0244 - categorical_accuracy: 0.3463 - val_loss: 0.0487 - val_categorical_accuracy: 0.346827s - loss: 0.0235 - categorica - ETA: 20s - loss: 0.0240 - categorical_accuracy - ETA: 17s - loss: 0.0242 - categorical_ac - ETA: 14s - loss: 0.0242 - categorical_ac - ETA: 10s - loss: 0.0244 - categorical_ac - ETA: 8s - loss: 0.0245 - categorical_accuracy - ETA: 7s - loss: 0.0245 - categorical_accura - ETA: 6s - loss: 0.0245  - ETA: 3s - loss: 0.0244 - categorical_accu - ETA: 2s - loss: 0.0244 - cate\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0241 - categorical_accuracy: 0.3493 - val_loss: 0.0493 - val_categorical_accuracy: 0.3318A: 12s - loss: 0.0240 - categorical_accurac - ETA: 9s - loss: 0.0240 - categorical - E - ETA: 0s - loss: 0.0241 - categorical_accuracy: 0. - ETA: 0s - loss: 0.0241 - categorical_accuracy: 0.\n",
      "Epoch 85/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0244 - categorical_accuracy: 0.3468 - val_loss: 0.0488 - val_categorical_accuracy: 0.3357\n",
      "Epoch 86/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0244 - categorical_accuracy: 0.3484 - val_loss: 0.0481 - val_categorical_accuracy: 0.3529tegorical_accura - ETA: 15s - loss: 0.0250 - categorical_a - ETA: 12s - loss: 0.0249 - categorical - ETA: \n",
      "Epoch 87/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0236 - categorical_accuracy: 0.3524 - val_loss: 0.0494 - val_categorical_accuracy: 0.3429 ETA: 9s - loss: 0.0235\n",
      "Epoch 88/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0262 - categorical_accuracy: 0.3420 - val_loss: 0.0533 - val_categorical_accuracy: 0.3155rical_accuracy: 0.34\n",
      "Epoch 89/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0279 - categorical_accuracy: 0.3333 - val_loss: 0.0509 - val_categorical_accuracy: 0.333723s - loss: 0.0315 - categor - ETA: 19s - loss: 0.0313 - categor - ETA: 15s - loss: 0.0305 - categorical_accuracy: 0.322 - ETA: 15s - loss: 0.0304 - categorical_\n",
      "Epoch 90/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0253 - categorical_accuracy: 0.3440 - val_loss: 0.0488 - val_categorical_accuracy: 0.3397oss: 0.0260  - ETA: 7s - loss: 0.0253 - categorical_accuracy: 0.34 - ETA: 7s - loss: 0.0253 - categori\n",
      "Epoch 91/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0241 - categorical_accuracy: 0.3503 - val_loss: 0.0485 - val_categorical_accuracy: 0.3462categorical_accu - ETA: 2s - loss: 0.0242 - \n",
      "Epoch 92/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0249 - categorical_accuracy: 0.3469 - val_loss: 0.0477 - val_categorical_accuracy: 0.3426loss: 0.0270 - categorical_ - ETA: 11s - loss: 0.0252 -\n",
      "Epoch 93/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0232 - categorical_accuracy: 0.3538 - val_loss: 0.0489 - val_categorical_accuracy: 0.3374\n",
      "Epoch 94/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0226 - categorical_accuracy: 0.3575 - val_loss: 0.0473 - val_categorical_accuracy: 0.3526\n",
      "Epoch 95/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0222 - categorical_accuracy: 0.3591 - val_loss: 0.0493 - val_categorical_accuracy: 0.3479TA: 16s - ETA: 7s - loss: 0.0222  - ETA: 4s - loss:\n",
      "Epoch 96/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0223 - categorical_accuracy: 0.3592 - val_loss: 0.0511 - val_categorical_accuracy: 0.3432\n",
      "Epoch 97/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0279 - categorical_accuracy: 0.3368 - val_loss: 0.0523 - val_categorical_accuracy: 0.3254\n",
      "Epoch 98/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0231 - categorical_accuracy: 0.3538 - val_loss: 0.0475 - val_categorical_accuracy: 0.3585al_accuracy: 0.3 - ETA: 16s - loss: 0.0241 - cat - ETA: 11s - loss: 0.0 - ETA: 7s - los - ETA: 3s - l\n",
      "Epoch 99/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0213 - categorical_accuracy: 0.3616 - val_loss: 0.0468 - val_categorical_accuracy: 0.3636TA: 17s - loss: 0.0215 - categoric - ETA: 11s - loss: 0. - ETA: 6s - los - ETA: 1s - loss: 0.0212 - categorical_accuracy: 0.36 - ETA: 1s - loss: 0.0213 - categorical_ac\n",
      "Epoch 100/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0210 - categorical_accuracy: 0.3652 - val_loss: 0.0492 - val_categorical_accuracy: 0.3359\n",
      "Epoch 101/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0213 - categorical_accuracy: 0.3624 - val_loss: 0.0474 - val_categorical_accuracy: 0.3505\n",
      "Epoch 102/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0249 - categorical_accuracy: 0.3490 - val_loss: 0.0505 - val_categorical_accuracy: 0.3396-  - ETA: 1s - loss: 0.0249 - categori\n",
      "Epoch 103/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0228 - categorical_accuracy: 0.3607 - val_loss: 0.0464 - val_categorical_accuracy: 0.36070.0237 - categori - ETA: 8s - loss: 0.0234 - categorical_ac\n",
      "Epoch 104/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0206 - categorical_accuracy: 0.3669 - val_loss: 0.0472 - val_categorical_accuracy: 0.3675curacy: - ETA: 8s - loss: 0.0206 - cate - ETA: 5s - loss: 0.0205 - categorical_accuracy: 0. - ETA: 4s - los\n",
      "Epoch 105/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0220 - categorical_accuracy: 0.3631 - val_loss: 0.0483 - val_categorical_accuracy: 0.3466\n",
      "Epoch 106/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0215 - categorical_accuracy: 0.3651 - val_loss: 0.0472 - val_categorical_accuracy: 0.35475s - loss: 0.0220 - categori - ETA: 9s - loss: 0.0213 - categorical_accu - ETA: 7s - loss: 0.0213 - \n",
      "Epoch 107/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0204 - categorical_accuracy: 0.3681 - val_loss: 0.0460 - val_categorical_accuracy: 0.3599A: 2s - loss: 0.0204 - ca\n",
      "Epoch 108/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0196 - categorical_accuracy: 0.3699 - val_loss: 0.0458 - val_categorical_accuracy: 0.3679\n",
      "Epoch 109/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0193 - categorical_accuracy: 0.3721 - val_loss: 0.0459 - val_categorical_accuracy: 0.364123s - loss: 0.0189 - categorical_accur\n",
      "Epoch 110/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0193 - categorical_accuracy: 0.3715 - val_loss: 0.0475 - val_categorical_accuracy: 0.3622\n",
      "Epoch 111/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0192 - categorical_accuracy: 0.3721 - val_loss: 0.0457 - val_categorical_accuracy: 0.3602\n",
      "Epoch 112/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0192 - categorical_accuracy: 0.3742 - val_loss: 0.0474 - val_categorical_accuracy: 0.3592ical_accuracy: 0. - ETA: 3s - loss: 0.0191 - categorical_ - ETA: 1s - loss: 0.0191 - categorica\n",
      "Epoch 113/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0200 - categorical_accuracy: 0.3696 - val_loss: 0.0487 - val_categorical_accuracy: 0.3671\n",
      "Epoch 114/500\n",
      "4421/4421 [==============================] - 30s 7ms/step - loss: 0.0272 - categorical_accuracy: 0.3438 - val_loss: 0.0544 - val_categorical_accuracy: 0.3304.0 - ETA: 7s - - ETA: 3s - loss:\n",
      "Epoch 115/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0278 - categorical_accuracy: 0.3439 - val_loss: 0.0506 - val_categorical_accuracy: 0.3470: 19s - loss: 0.0289 - categor - ETA: 12s - loss: 0.0291 - ca - ETA: 0s - loss: 0.0279 - categorical_accuracy: \n",
      "Epoch 116/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0222 - categorical_accuracy: 0.3609 - val_loss: 0.0476 - val_categorical_accuracy: 0.3601\n",
      "Epoch 117/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0207 - categorical_accuracy: 0.3701 - val_loss: 0.0457 - val_categorical_accuracy: 0.3664\n",
      "Epoch 118/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0191 - categorical_accuracy: 0.3737 - val_loss: 0.0455 - val_categorical_accuracy: 0.3561 25s - loss: 0.0195 - categorical_accuracy: 0.3 - ETA: 24s - loss: 0.0194 - categorical_accura - ETA: 21s - loss: 0.0193 - - ETA: 13s - loss: 0.0192 - categorical_accurac - ETA: 11s - loss: 0.0192 - categoric - ETA: 8s - loss: 0.0192 - categorical_ac - ETA: 7s - ETA: 2s - loss: 0.0192 - \n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0186 - categorical_accuracy: 0.3742 - val_loss: 0.0449 - val_categorical_accuracy: 0.375913s - loss: 0.0183 - categorical_accuracy: 0.3 - ETA: 12s - loss: 0.0183 - categorical_a - ETA: 9s - ETA: 2s - loss: 0.0185 - ca\n",
      "Epoch 120/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0180 - categorical_accuracy: 0.3771 - val_loss: 0.0452 - val_categorical_accuracy: 0.37030182 - categorical_accuracy: 0 - ETA: 20s - loss: 0.0183 - categorical_accuracy: 0.38 - ETA: 20s - loss: 0.0183 - categorical_accuracy: 0.37 - ETA: 19s - loss: 0.0184 - categorical_accuracy:  - ETA: - ETA: 3s - loss: 0.0181 - categorical_accuracy: 0.37 - ETA: 3s - loss: 0.018\n",
      "Epoch 121/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0177 - categorical_accuracy: 0.3786 - val_loss: 0.0454 - val_categorical_accuracy: 0.3750TA: 11s - loss: 0.0180 - categorical_accuracy: 0.37 - \n",
      "Epoch 122/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0186 - categorical_accuracy: 0.3757 - val_loss: 0.0465 - val_categorical_accuracy: 0.3646\n",
      "Epoch 123/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0185 - categorical_accuracy: 0.3788 - val_loss: 0.0462 - val_categorical_accuracy: 0.3701\n",
      "Epoch 124/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0183 - categorical_accuracy: 0.3776 - val_loss: 0.0455 - val_categorical_accuracy: 0.3664\n",
      "Epoch 125/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0174 - categorical_accuracy: 0.3810 - val_loss: 0.0449 - val_categorical_accuracy: 0.3736\n",
      "Epoch 126/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0170 - categorical_accuracy: 0.3821 - val_loss: 0.0447 - val_categorical_accuracy: 0.3777gorical_accuracy:  - ETA: 16s - loss: 0.0172 - categorical_accuracy: 0.382 - ETA: 16s - loss: 0.0172 - categorical_accuracy: 0.38 - ETA: 16s - loss: 0.0171 - catego - ETA: 10s - loss - ETA - ETA: 0s - loss: 0.0170 - categorical_accuracy: 0. - ETA: 0s - loss: 0.0169 - categorical_accuracy: 0.38\n",
      "Epoch 127/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0180 - categorical_accuracy: 0.3805 - val_loss: 0.0441 - val_categorical_accuracy: 0.3656loss: 0.0181 - categorical_accuracy: 0.38 - ETA: 9s - loss: 0.0 - ETA: 4s - los\n",
      "Epoch 128/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0174 - categorical_accuracy: 0.3810 - val_loss: 0.0469 - val_categorical_accuracy: 0.3697\n",
      "Epoch 129/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0185 - categorical_accuracy: 0.3782 - val_loss: 0.0464 - val_categorical_accuracy: 0.3763 - categorical_accuracy: 0. - ETA: 19s - l\n",
      "Epoch 130/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0169 - categorical_accuracy: 0.3841 - val_loss: 0.0452 - val_categorical_accuracy: 0.3783\n",
      "Epoch 131/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0164 - categorical_accuracy: 0.3833 - val_loss: 0.0450 - val_categorical_accuracy: 0.3743TA: 3s - loss: 0.0163 - categorical_accuracy - ETA: 2s - loss: 0.0163 - catego\n",
      "Epoch 132/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0158 - categorical_accuracy: 0.3858 - val_loss: 0.0444 - val_categorical_accuracy: 0.3795\n",
      "Epoch 133/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0226 - categorical_accuracy: 0.3617 - val_loss: 0.0465 - val_categorical_accuracy: 0.3590oss: 0.0261 - categorical_accuracy: 0.350 - ETA: 15s - loss: 0.0260 -  - ETA: 9s - loss: 0.0247 - categorical_accuracy: 0.3 - ETA: 9s - loss: 0.0246 - ca - ETA: 7s - loss: 0.0241 - categori\n",
      "Epoch 134/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0175 - categorical_accuracy: 0.3796 - val_loss: 0.0474 - val_categorical_accuracy: 0.3557\n",
      "Epoch 135/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0269 - categorical_accuracy: 0.3475 - val_loss: 0.0509 - val_categorical_accuracy: 0.3672 4s - loss: 0\n",
      "Epoch 136/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0192 - categorical_accuracy: 0.3749 - val_loss: 0.0464 - val_categorical_accuracy: 0.3705\n",
      "Epoch 137/500\n",
      "4421/4421 [==============================] - 33s 8ms/step - loss: 0.0173 - categorical_accuracy: 0.3822 - val_loss: 0.0443 - val_categorical_accuracy: 0.3667175 -  - ETA: 8s - loss: 0\n",
      "Epoch 138/500\n",
      "4421/4421 [==============================] - 33s 7ms/step - loss: 0.0164 - categorical_accuracy: 0.3854 - val_loss: 0.0447 - val_categorical_accuracy: 0.3788TA: 31s - loss: 0.0166 - categorical_accuracy: 0.38 - ETA: 29s - loss: 0.0165 - categor - ETA: 2s - loss: 0.0163 - categorical_accu - ETA: 0s - loss: 0.0163 - categorical_accura\n",
      "Epoch 139/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0161 - categorical_accuracy: 0.3829 - val_loss: 0.0445 - val_categorical_accuracy: 0.3700-\n",
      "Epoch 140/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0158 - categorical_accuracy: 0.3867 - val_loss: 0.0444 - val_categorical_accuracy: 0.3774\n",
      "Epoch 141/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0153 - categorical_accuracy: 0.3871 - val_loss: 0.0440 - val_categorical_accuracy: 0.37160.0155 - categorical_ - ETA: 16s - loss: 0.0155 - categorical_accuracy: 0.3 - ETA: 16s - loss: 0.0153 - ca\n",
      "Epoch 142/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0155 - categorical_accuracy: 0.3881 - val_loss: 0.0457 - val_categorical_accuracy: 0.3802 0.0156 - cate - ETA: 11s - loss: 0.01 - ETA: 7s - los - ETA: 2s - loss: 0.0154 \n",
      "Epoch 143/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0162 - categorical_accuracy: 0.3858 - val_loss: 0.0444 - val_categorical_accuracy: 0.3809categorical_accura\n",
      "Epoch 144/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0159 - categorical_accuracy: 0.3892 - val_loss: 0.0451 - val_categorical_accuracy: 0.3758\n",
      "Epoch 145/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0148 - categorical_accuracy: 0.3904 - val_loss: 0.0435 - val_categorical_accuracy: 0.3773\n",
      "Epoch 146/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0150 - categorical_accuracy: 0.3906 - val_loss: 0.0442 - val_categorical_accuracy: 0.3784cal_acc - ETA: 12s - loss: 0.0151 - categorical_accuracy:  - ETA: 1\n",
      "Epoch 147/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0149 - categorical_accuracy: 0.3916 - val_loss: 0.0499 - val_categorical_accuracy: 0.3702a\n",
      "Epoch 148/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0152 - categorical_accuracy: 0.3869 - val_loss: 0.0446 - val_categorical_accuracy: 0.3837\n",
      "Epoch 149/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0145 - categorical_accuracy: 0.3915 - val_loss: 0.0445 - val_categorical_accuracy: 0.3824s - loss: 0.0139 - categorical_accura - ETA: 19s -\n",
      "Epoch 150/500\n",
      "4421/4421 [==============================] - 32s 7ms/step - loss: 0.0147 - categorical_accuracy: 0.3898 - val_loss: 0.0444 - val_categorical_accuracy: 0.3814oss: 0.0146 - categorical_accuracy: \n",
      "Epoch 151/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0141 - categorical_accuracy: 0.3919 - val_loss: 0.0447 - val_categorical_accuracy: 0.3835\n",
      "Epoch 152/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0148 - categorical_accuracy: 0.3894 - val_loss: 0.0450 - val_categorical_accuracy: 0.3871\n",
      "Epoch 153/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0146 - categorical_accuracy: 0.3927 - val_loss: 0.0450 - val_categorical_accuracy: 0.3814\n",
      "Epoch 154/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0162 - categorical_accuracy: 0.3869 - val_loss: 0.0460 - val_categorical_accuracy: 0.3779 - categorical_accuracy: 0 - ETA: 4s - loss: 0.0165 - categorical_accuracy:  - ETA: 3s - loss: 0.0164 - categorica - ETA: 1s - loss: 0.0163 - categorical_accuracy: 0. - ETA: 1s - loss: 0.0163 - categorical_\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0164 - categorical_accuracy: 0.3849 - val_loss: 0.0489 - val_categorical_accuracy: 0.36850156 - categorical_accura - ETA: 12s - los - ETA: 5s - loss: 0.0157 - catego - ETA: 3s - loss: 0.0160 - \n",
      "Epoch 156/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0177 - categorical_accuracy: 0.3815 - val_loss: 0.0466 - val_categorical_accuracy: 0.3789ss: 0.0177 - categorical_accura\n",
      "Epoch 157/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0159 - categorical_accuracy: 0.3890 - val_loss: 0.0449 - val_categorical_accuracy: 0.3774A: 24s - loss: 0.0170 - categorical_ac\n",
      "Epoch 158/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0149 - categorical_accuracy: 0.3921 - val_loss: 0.0453 - val_categorical_accuracy: 0.3883 9s - loss: 0.0147 - catego - ETA: 7s - loss: 0.0147 - categorical_accuracy - ETA: 6s - loss: 0.0148 - categorical_accura - ETA:  - ETA: 0s - loss: 0.0148 - categorical_accu\n",
      "Epoch 159/500\n",
      "4421/4421 [==============================] - 35s 8ms/step - loss: 0.0145 - categorical_accuracy: 0.3903 - val_loss: 0.0449 - val_categorical_accuracy: 0.3917\n",
      "Epoch 160/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0144 - categorical_accuracy: 0.3919 - val_loss: 0.0449 - val_categorical_accuracy: 0.3849 6s - loss: 0.0146 - catego - ETA: 3s - loss: 0.0\n",
      "Epoch 161/500\n",
      "4421/4421 [==============================] - 36s 8ms/step - loss: 0.0138 - categorical_accuracy: 0.3951 - val_loss: 0.0442 - val_categorical_accuracy: 0.3874\n",
      "Epoch 162/500\n",
      "4421/4421 [==============================] - 31s 7ms/step - loss: 0.0138 - categorical_accuracy: 0.3931 - val_loss: 0.0441 - val_categorical_accuracy: 0.3756 - ETA: 8s - loss: 0.0 - ETA: 5s - loss: 0.0138 - categorical_accuracy: 0.\n",
      "Epoch 163/500\n",
      "4421/4421 [==============================] - 34s 8ms/step - loss: 0.0135 - categorical_accuracy: 0.3941 - val_loss: 0.0444 - val_categorical_accuracy: 0.38020s - loss: 0.0137 - categorical_accura - ETA\n",
      "Epoch 164/500\n",
      "4421/4421 [==============================] - 38s 9ms/step - loss: 0.0134 - categorical_accuracy: 0.3932 - val_loss: 0.0436 - val_categorical_accuracy: 0.3861\n",
      "Epoch 165/500\n",
      "4421/4421 [==============================] - 37s 8ms/step - loss: 0.0137 - categorical_accuracy: 0.3929 - val_loss: 0.0440 - val_categorical_accuracy: 0.3812\n",
      "Epoch 166/500\n",
      "4421/4421 [==============================] - 33s 8ms/step - loss: 0.0130 - categorical_accuracy: 0.3936 - val_loss: 0.0440 - val_categorical_accuracy: 0.3808\n",
      "Epoch 167/500\n",
      "2176/4421 [=============>................] - ETA: 19s - loss: 0.0131 - categorical_accuracy: 0.3989- ETA: 25s - loss: 0.0131 - categorical_acc"
     ]
    }
   ],
   "source": [
    "# Want to penalize each output node independantly. \n",
    "# Log Loss aka multi-class multi-label as sigmoid -> binary CE, as want probs to be considered independent of each other.\n",
    "# Combo of sigmoid and crossentropy here log counteracts exp to reduce the saturation :)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # consider changing this one for others\n",
    "              metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(time()))\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5, verbose=0, mode=\"auto\")\n",
    "\n",
    "print(train_xs.shape, train_composers.shape, train_ys.shape)\n",
    "model.fit([train_xs, train_composers], train_ys,\n",
    "          epochs=500, # Train harder more for more things was too bad train man :(\n",
    "          batch_size=32,\n",
    "          shuffle=True, # shuffle here but not when constructing set to be able to validate later on :)\n",
    "          #callbacks=[tensorboard, early_stop],\n",
    "          validation_data=([test_xs, test_composers], test_ys),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save(\"./models/nostate_32_offset_2_specialist.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model.predict([train_xs, train_composers], verbose=True)\n",
    "maxes = [np.max(c) for c in a]\n",
    "plt.hist(maxes)\n",
    "plt.show()\n",
    "plt.hist(a[:,-1])\n",
    "plt.show()\n",
    "b = np.max(a[1][-1])\n",
    "plt.plot(a[1][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[0].T, fs=2)\n",
    "prep.visualize_piano_roll(train_xs[0].T, fs=2)\n",
    "plt.plot(a[100][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[100].T, fs=2)\n",
    "prep.visualize_piano_roll(train_xs[100].T, fs=2)\n",
    "plt.plot(a[200][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[200].T, fs=2)\n",
    "prep.visualize_piano_roll(train_xs[200].T, fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_song_from_predict(model, initial_data, composer, limit):\n",
    "    song = []\n",
    "    keep_producing = True\n",
    "    prev_data = initial_data\n",
    "    while keep_producing and len(song) < limit:\n",
    "        predictions = model.predict([np.array([prev_data]), composer])[0]\n",
    "        labels = np.zeros(128)\n",
    "        labels[predictions[-1]/np.max(predictions[-1])>0.5] = 1 # Threshold to consider the key as active, binarized based on this\n",
    "        keep_producing = np.sum(labels) != len(labels)\n",
    "        song.append(labels)\n",
    "        prev_data = np.append(prev_data[1:], [labels], 0)\n",
    "    return np.array(song)\n",
    "\n",
    "initial_step = 123\n",
    "steps = 10\n",
    "song1 = make_song_from_predict(model, train_xs[initial_step], np.array([[1.0, 0.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song2 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 1.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song3 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 1.0, 0.0]]), sequence_length*steps)\n",
    "song4 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 0.0, 1.0]]), sequence_length*steps)\n",
    "prep.embed_play_v1(song1.T, fs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song2.T, fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song3.T, fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song4.T, fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from assignment.helpers import datapreparation as prep\n",
    "\n",
    "\n",
    "fs2_dirpath = \"./assignment/datasets/training/piano_roll_fs2\"\n",
    "\n",
    "\n",
    "# Load initial data\n",
    "datasets = prep.load_all_dataset(fs2_dirpath)\n",
    "dataset_names = prep.load_all_dataset_names(fs2_dirpath)\n",
    "unique_names = set()\n",
    "for name in dataset_names: # Make sure the same names get the same encoding each run\n",
    "    unique_names.add(name)\n",
    "unique_names = list(unique_names)\n",
    "name_to_int = dict([(unique_names[i], i) for i in range(len(unique_names))])\n",
    "int_to_name = dict([(i, unique_names[i]) for i in range(len(unique_names))])\n",
    "dataset_names = to_categorical([name_to_int[name] for name in dataset_names]) # one-hot encode the composers\n",
    "datasets = [dataset[:, 1:] for dataset in datasets] # Remove the headers\n",
    "\n",
    "# Setting initial parameters\n",
    "dataset_id_names = dict(zip(np.arange(len(dataset_names)), dataset_names))\n",
    "longest_song = max(datasets[i].shape[1] for i in range(len(datasets)))\n",
    "sequence_length = 32\n",
    "length = longest_song//sequence_length + 1\n",
    "num_keys = len(datasets[0])\n",
    "parts_per_song = int(longest_song/sequence_length)\n",
    "composer_encoding_len=len(dataset_names[0]) # 4 composers\n",
    "\n",
    "# Makes several datasets from this first one with differing intervals between to capture the \"gaps\" between two sequences\n",
    "# Add each subsequence of each song with differing offsets ([0:10], [1:11], [2:12], ...) to retain information.\n",
    "# Unable to implement stateful, so try to retain as much information between subsequences as possible. \n",
    "# Also a way of dataset augmentation (regularization) by increasing the size of the dataset\n",
    "\n",
    "def transpose_and_label_more(dataset_names, datasets, num_keys):\n",
    "    zs = []\n",
    "    datasets_transposed = np.array([(datasets[i].T, dataset_names[i]) for i in range(len(datasets))])\n",
    "    for song, composer in datasets_transposed:\n",
    "        for offset in range(0, sequence_length, 2):\n",
    "            for i in range(0, len(song)//sequence_length-offset):\n",
    "                x = song[offset+i*sequence_length:offset+(i+1)*sequence_length]\n",
    "                if i == len(song)//sequence_length - (1+offset): # Add the EOF marker if last seq of song\n",
    "                    y = np.append(song[offset+i*sequence_length+1:offset+(i+1)*sequence_length], np.array([np.ones(num_keys)]), 0)\n",
    "                else:\n",
    "                    y = song[offset+i*sequence_length+1:offset+(i+1)*sequence_length+1]\n",
    "                zs.append((x, y, composer))\n",
    "    np.random.shuffle(zs)\n",
    "    xs, ys, composers = [], [], []\n",
    "    for x, y, composer in zs:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        composers.append(composer)\n",
    "    return np.array(xs), np.array(ys), np.array(composers)\n",
    "\n",
    "train_xs, train_ys, train_composers = transpose_and_label_more(dataset_names, datasets, num_keys)\n",
    "test_xs = train_xs[int(len(train_xs)*0.8):]\n",
    "train_xs = train_xs[:int(len(train_xs)*0.8)]\n",
    "test_ys = train_ys[int(len(train_ys)*0.8):]\n",
    "train_ys = train_ys[:int(len(train_ys)*0.8)]\n",
    "test_composers = train_composers[int(len(train_composers)*0.8):]\n",
    "train_composers = train_composers[:int(len(train_composers)*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = load_model(\"./models/nostate_32_offset_2_specialist.h5f\")\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "print(model.summary())\n",
    "a = model.evaluate([train_xs, train_composers], train_ys,\n",
    "          batch_size=32)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_song_from_predict(model, initial_data, composer, limit):\n",
    "    song = []\n",
    "    keep_producing = True\n",
    "    prev_data = initial_data\n",
    "    while keep_producing and len(song) < limit:\n",
    "        predictions = model.predict([np.array([prev_data]), composer])[0]\n",
    "        labels = np.zeros(128)\n",
    "        #labels[predictions[-1]/np.max(predictions[-1])>0.75] = 1 # Threshold to consider the key as active, binarized based on this\n",
    "        labels[predictions[-1]>0.5] = 1\n",
    "        keep_producing = np.sum(labels) != len(labels)\n",
    "        song.append(labels)\n",
    "        prev_data = np.append(prev_data[1:], [labels], 0)\n",
    "    return np.array(song)\n",
    "\n",
    "initial_step = 2\n",
    "steps = 10\n",
    "actual = train_xs[initial_step+1]\n",
    "for i in range(1, steps):\n",
    "    actual = np.append(actual, train_xs[initial_step+1+i], axis=0)\n",
    "song1 = make_song_from_predict(model, train_xs[initial_step], np.array([[1.0, 0.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song2 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 1.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song3 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 1.0, 0.0]]), sequence_length*steps)\n",
    "song4 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 0.0, 1.0]]), sequence_length*steps)\n",
    "print(int_to_name[0])\n",
    "prep.visualize_piano_roll(song1.T, fs=2)\n",
    "print(int_to_name[1])\n",
    "prep.visualize_piano_roll(song2.T, fs=2)\n",
    "print(int_to_name[2])\n",
    "prep.visualize_piano_roll(song3.T, fs=2)\n",
    "print(int_to_name[3])\n",
    "prep.visualize_piano_roll(song4.T, fs=2)\n",
    "print(int_to_name[list(train_composers[initial_step]).index(1)])\n",
    "prep.visualize_piano_roll(actual.T, fs=2)\n",
    "prep.embed_play_v1(actual.T, fs=2)\n",
    "song1_volume = np.zeros(song1.shape)\n",
    "song1_volume[song1>0] = 100\n",
    "song2_volume = np.zeros(song2.shape)\n",
    "song2_volume[song2>0] = 100\n",
    "song3_volume = np.zeros(song3.shape)\n",
    "song3_volume[song3>0] = 100\n",
    "song4_volume = np.zeros(song4.shape)\n",
    "song4_volume[song4>0] = 100\n",
    "actual_volume = np.zeros(actual.shape)\n",
    "actual_volume[actual>0] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.piano_roll_to_mid_file(song1_volume.T, \"song1.midi\", fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.piano_roll_to_mid_file(song2_volume.T, \"song2.midi\", fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.piano_roll_to_mid_file(song3_volume.T, \"song3.midi\", fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.piano_roll_to_mid_file(song4_volume.T, \"song4.midi\", fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prep.piano_roll_to_mid_file(actual_volume.T, \"actual.midi\", fs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_