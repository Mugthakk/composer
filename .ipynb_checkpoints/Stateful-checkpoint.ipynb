{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 43, 10, 128)\n",
      "(84, 43, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.layers import LSTM, Dropout, Dense, BatchNormalization, Activation, Input, TimeDistributed, Masking\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU, PReLU\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "from assignment.helpers import datapreparation as prep\n",
    "\n",
    "\n",
    "# Can make the midi actually play by multiply the notes (0-128, so 1 is basically silence).\n",
    "\n",
    "# Note on specifying the initial state of RNNs\n",
    "# Seems as though you can reset state (probably stateful=True), and then pass an array of initial states that can be used\n",
    "# in the RNN - so initialize based on composer :D\n",
    "# https://keras.io/layers/recurrent/\n",
    "\n",
    "fs1_dirpath = \"./assignment/datasets/training/piano_roll_fs1\"\n",
    "\n",
    "datasets = prep.load_all_dataset(fs1_dirpath)\n",
    "dataset_names = prep.load_all_dataset_names(fs1_dirpath)\n",
    "\n",
    "datasets = [dataset[:, 1:] for dataset in datasets] # Remove the headers\n",
    "\n",
    "dataset_id_names = dict(zip(np.arange(len(dataset_names)), dataset_names))\n",
    "longest_song = max(datasets[i].shape[1] for i in range(len(datasets)))\n",
    "sequence_length = 10\n",
    "num_batches = longest_song//sequence_length + 1\n",
    "num_keys = len(datasets[0])\n",
    "pad_length = number_of_batches*sequence_length\n",
    "num_songs = len(datasets)\n",
    "b_size = 21 # feed one and one to control reset states for stateful, hella slow though :(\n",
    "\n",
    "def preprocess_for_stateful_with_padding(dataset, num_songs, sequence_length, num_batches, num_keys, pad_length):\n",
    "    big_af = [[[] for a in range(num_songs)] for b in range(num_batches)]\n",
    "    songs_padded = pad_sequences(dataset, maxlen=pad_length, padding=\"post\", value=np.array([-1.0 for _ in range(num_keys)]))\n",
    "    for i in range(num_batches):\n",
    "        for j in range(num_songs):\n",
    "            big_af[i][j] = songs_padded[j, i*sequence_length:(i+1)*sequence_length]\n",
    "    return np.array(big_af)\n",
    "\n",
    "def preprocess_for_3d(dataset, num_songs, sequence_length, num_batches, num_keys, pad_length):\n",
    "    big_af = [[] for song in dataset]\n",
    "    songs_padded = pad_sequences(dataset, maxlen=pad_length, padding=\"post\", value=np.array([-1.0 for _ in range(num_keys)]))\n",
    "    for i in range(num_songs):\n",
    "        for j in range(num_batches):\n",
    "            big_af[i].append([songs_padded[i,j*sequence_length:(j+1)*sequence_length]])\n",
    "    return np.array(big_af)\n",
    "\n",
    "datasets = np.array([dataset.T for dataset in datasets])\n",
    "xs = preprocess_for_stateful_with_padding(datasets, num_songs, sequence_length, num_batches, num_keys, pad_length)\n",
    "datasets_labels = np.array([np.append(dataset[1:,:], np.array([np.ones(num_keys)]), axis=0) for dataset in datasets])\n",
    "ys = preprocess_for_stateful_with_padding(datasets_labels, num_songs, sequence_length, num_batches, num_keys, pad_length)\n",
    "print(xs.shape)\n",
    "print(ys.shape)\n",
    "# 84 batches x 43 songs x 10 time_steps x 128 piano_keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(batch_shape=(b_size, num_songs, sequence_length, num_keys))\n",
    "mask = TimeDistributed(Masking(mask_value=-1.0))(inputs)\n",
    "# Units = units per timestep LSTM block, i.e. output dimensionality (128 here since input and output 128 keys)\n",
    "lstm1 = TimeDistributed(LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True,\n",
    "               stateful=True,\n",
    "               dropout=0.0, #0.2, #0.25,\n",
    "               recurrent_dropout=0.0, #0.25,\n",
    "               kernel_regularizer=None,#l2(0.0001),\n",
    "               recurrent_regularizer=None, #l2(0.0001),\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,#l2(0.0001),\n",
    "               ))(inputs)\n",
    "normalized1 = TimeDistributed(BatchNormalization())(lstm1)\n",
    "dense1 = TimeDistributed(Dense(num_keys, activation=\"sigmoid\"))(normalized1)\n",
    "lstm2 = TimeDistributed(LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True,\n",
    "               stateful=True,\n",
    "               dropout=0.0, #0.2, #0.25,\n",
    "               recurrent_dropout=0.0, #0.25,\n",
    "               kernel_regularizer=None,#l2(0.0001),\n",
    "               recurrent_regularizer=None, #l2(0.0001),\n",
    "               bias_regularizer=None,\n",
    "               activity_regularizer=None,#l2(0.0001),\n",
    "               ))(dense1)\n",
    "normalized2 = TimeDistributed(BatchNormalization())(lstm2)\n",
    "dense2 = TimeDistributed(Dense(num_keys, activation=\"sigmoid\"))(normalized2)\n",
    "outputs = Dense(num_keys, activation=\"sigmoid\")(normalized2) # Sigmoid keeps the probabilities independent of each other, while softmax does not!\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "rmsprop = RMSprop(lr=0.001)\n",
    "adagrad =  Adagrad(lr=0.001)\n",
    "adam = Adam(lr=0.001, amsgrad=True) #Ends up in a point where gradients really small, denominator really small and then loss exploding\n",
    "adadelta = Adadelta(lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (21, 43, 10, 128)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_53 (TimeDis (21, 43, 10, 128)         131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_54 (TimeDis (21, 43, 10, 128)         512       \n",
      "_________________________________________________________________\n",
      "time_distributed_55 (TimeDis (21, 43, 10, 128)         16512     \n",
      "_________________________________________________________________\n",
      "time_distributed_56 (TimeDis (21, 43, 10, 128)         131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_57 (TimeDis (21, 43, 10, 128)         512       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (21, 43, 10, 128)         16512     \n",
      "=================================================================\n",
      "Total params: 297,216\n",
      "Trainable params: 296,704\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 8s 96ms/step - loss: 0.6320 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 6s 67ms/step - loss: 0.2673 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 8s 92ms/step - loss: -1.5612 - categorical_accuracy: 5.2602e-04\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 6s 71ms/step - loss: -4.1367 - categorical_accuracy: 0.0029\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 6s 76ms/step - loss: -6.6237 - categorical_accuracy: 0.0030\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 6s 76ms/step - loss: -8.0155 - categorical_accuracy: 0.0233\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 8s 99ms/step - loss: -8.6629 - categorical_accuracy: 0.2061\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -8.9987 - categorical_accuracy: 0.2551\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.1965 - categorical_accuracy: 0.3201\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.3270 - categorical_accuracy: 0.3676\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 9s 105ms/step - loss: -9.4389 - categorical_accuracy: 0.3855\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 6s 67ms/step - loss: -9.5269 - categorical_accuracy: 0.3859\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 7s 83ms/step - loss: -9.5978 - categorical_accuracy: 0.4323\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 8s 98ms/step - loss: -9.6537 - categorical_accuracy: 0.4493\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 10s 120ms/step - loss: -9.6944 - categorical_accuracy: 0.4496\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 11s 126ms/step - loss: -9.7211 - categorical_accuracy: 0.4500\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 11s 131ms/step - loss: -9.7405 - categorical_accuracy: 0.4500\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 10s 122ms/step - loss: -9.7559 - categorical_accuracy: 0.4500\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 11s 127ms/step - loss: -9.7670 - categorical_accuracy: 0.4507\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 11s 136ms/step - loss: -9.7756 - categorical_accuracy: 0.4510\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 11s 131ms/step - loss: -9.7826 - categorical_accuracy: 0.4510\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 9s 109ms/step - loss: -9.7886 - categorical_accuracy: 0.4511\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 6s 67ms/step - loss: -9.7944 - categorical_accuracy: 0.4511\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 7s 81ms/step - loss: -9.7982 - categorical_accuracy: 0.4512\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 10s 118ms/step - loss: -9.8014 - categorical_accuracy: 0.4524\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 10s 123ms/step - loss: -9.8045 - categorical_accuracy: 0.4872\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8075 - categorical_accuracy: 0.5149\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8103 - categorical_accuracy: 0.5149\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8128 - categorical_accuracy: 0.5149\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8150 - categorical_accuracy: 0.5149\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 8s 93ms/step - loss: -9.8166 - categorical_accuracy: 0.5149\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 6s 67ms/step - loss: -9.8177 - categorical_accuracy: 0.5149\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 7s 83ms/step - loss: -9.8184 - categorical_accuracy: 0.5149\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 10s 124ms/step - loss: -9.8187 - categorical_accuracy: 0.5149\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 10s 124ms/step - loss: -9.8188 - categorical_accuracy: 0.5149\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8190 - categorical_accuracy: 0.5149\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 10s 125ms/step - loss: -9.8191 - categorical_accuracy: 0.5149\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 10s 122ms/step - loss: -9.8192 - categorical_accuracy: 0.5149\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8194 - categorical_accuracy: 0.5148\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 6s 77ms/step - loss: -9.8195 - categorical_accuracy: 0.5148\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 6s 67ms/step - loss: -9.8197 - categorical_accuracy: 0.5148\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 8s 99ms/step - loss: -9.8198 - categorical_accuracy: 0.5146\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8200 - categorical_accuracy: 0.5145\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8202 - categorical_accuracy: 0.5142\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8204 - categorical_accuracy: 0.5137\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8207 - categorical_accuracy: 0.5133\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 10s 124ms/step - loss: -9.8210 - categorical_accuracy: 0.5129\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 10s 124ms/step - loss: -9.8213 - categorical_accuracy: 0.5127\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 10s 121ms/step - loss: -9.8220 - categorical_accuracy: 0.5122\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 6s 67ms/step - loss: -9.8232 - categorical_accuracy: 0.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x253a3faf550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want to penalize each output node independantly. So we pick a binary loss \n",
    "# and model the output of the network as a independent bernoulli distributions per label.\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # consider changing this one for others\n",
    "              metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(time()))\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=0, mode=\"auto\")\n",
    "\n",
    "\n",
    "model.fit(xs, ys, batch_size=b_size, epochs=50, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 2s 28ms/step\n",
      "[<keras.engine.input_layer.InputLayer object at 0x0000025397486A58>, <keras.layers.wrappers.TimeDistributed object at 0x0000025397486AC8>, <keras.layers.wrappers.TimeDistributed object at 0x00000253A41EAC88>, <keras.layers.wrappers.TimeDistributed object at 0x00000253A3B5D7B8>, <keras.layers.wrappers.TimeDistributed object at 0x0000025397767C88>, <keras.layers.wrappers.TimeDistributed object at 0x00000253976FEF28>, <keras.layers.core.Dense object at 0x000002539EE1F240>]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "x must have 2 or fewer dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c369afe2f839>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hanak\\venv\\music\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3135\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3136\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3137\u001b[1;33m                       stacked=stacked, normed=normed, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   3138\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3139\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hanak\\venv\\music\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1867\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mc:\\users\\hanak\\venv\\music\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   6578\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6579\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6580\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape_2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6581\u001b[0m         \u001b[0mnx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# number of datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hanak\\venv\\music\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_reshape_2D\u001b[1;34m(X, name)\u001b[0m\n\u001b[0;32m   2088\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2089\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2090\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} must have 2 or fewer dimensions\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x must have 2 or fewer dimensions"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = model.predict(xs, verbose=True, batch_size=b_size)\n",
    "print(model.layers)\n",
    "#print(model.layers[1].states[0])\n",
    "#print(model.layers[1].states[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix these\n",
    "maxes = [np.max(c) for c in a]\n",
    "plt.hist(maxes)\n",
    "plt.show()\n",
    "plt.hist(a[:,:,-1])\n",
    "plt.show()\n",
    "b = np.max(a[1][-1])\n",
    "plt.plot(a[0][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[0][0].T, fs=1)\n",
    "prep.visualize_piano_roll(xs[0][0].T, fs=1)\n",
    "plt.plot(a[100][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[1][0].T, fs=1)\n",
    "prep.visualize_piano_roll(xs[1][0].T, fs=1)\n",
    "plt.plot(a[200][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[2][0].T, fs=1)\n",
    "prep.visualize_piano_roll(xs[2][0].T, fs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_song_from_predict(model, initial_data, limit):\n",
    "    song = []\n",
    "    keep_producing = True\n",
    "    prev_data = initial_data\n",
    "    while keep_producing and len(song) < limit:\n",
    "        #print(\"input\", prev_data)\n",
    "        predictions = model.predict(np.array([prev_data]))[0]\n",
    "        #print(\"output\", predictions[-1])\n",
    "        #plt.plot(predictions[-1])\n",
    "        #plt.show()\n",
    "        labels = np.zeros(predictions.shape)\n",
    "        labels[predictions>0.5] = 1 # Weak activations, want to scale to 0/1\n",
    "        last_output = labels[-1]\n",
    "        #print(\"output scaled:\", last_output)\n",
    "        keep_producing = np.sum(last_output) != len(last_output)\n",
    "        song.append(last_output)\n",
    "        prev_data = np.append(prev_data[1:], [last_output], 0)\n",
    "    return np.array(song)\n",
    "\n",
    "initial_step = 1250\n",
    "song = make_song_from_predict(model, test_xs[initial_step], sequence_length)\n",
    "prep.visualize_piano_roll(song.T, fs=1)\n",
    "prep.visualize_piano_roll(test_xs[initial_step].T, fs=1)\n",
    "prep.embed_play_v1(song.T, fs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep.visualize_piano_roll(test_xs[initial_step+1].T, fs=1)\n",
    "prep.embed_play_v1(test_xs[initial_step+1].T, fs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
