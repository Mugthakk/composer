{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.layers import LSTM, Dropout, Dense, BatchNormalization, Activation, Input, TimeDistributed\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU, PReLU\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from assignment.helpers import datapreparation as prep\n",
    "\n",
    "\n",
    "\n",
    "fs1_dirpath = \"./assignment/datasets/training/piano_roll_fs1\"\n",
    "fs5_dirpath = \"./assignment/datasets/training/piano_roll_fs5\"\n",
    "\n",
    "\n",
    "# Load initial data\n",
    "datasets = prep.load_all_dataset(fs5_dirpath)\n",
    "dataset_names = prep.load_all_dataset_names(fs5_dirpath)\n",
    "unique_names = set()\n",
    "for name in dataset_names: # Make sure the same names get the same encoding each run\n",
    "    unique_names.add(name)\n",
    "unique_names = list(unique_names)\n",
    "name_to_int = dict([(unique_names[i], i) for i in range(len(unique_names))])\n",
    "int_to_name = dict([(i, unique_names[i]) for i in range(len(unique_names))])\n",
    "dataset_names = to_categorical([name_to_int[name] for name in dataset_names]) # one-hot encode the composers\n",
    "datasets = [dataset[:, 1:] for dataset in datasets] # Remove the headers\n",
    "\n",
    "# Setting initial parameters\n",
    "dataset_id_names = dict(zip(np.arange(len(dataset_names)), dataset_names))\n",
    "longest_song = max(datasets[i].shape[1] for i in range(len(datasets)))\n",
    "sequence_length = 40\n",
    "length = longest_song//sequence_length + 1\n",
    "num_keys = len(datasets[0])\n",
    "parts_per_song = int(longest_song/sequence_length)\n",
    "composer_encoding_len=len(dataset_names[0]) # 4 composers\n",
    "\n",
    "# Makes several datasets from this first one with differing intervals between to capture the \"gaps\" between two sequences\n",
    "# Add each subsequence of each song with differing offsets ([0:10], [1:11], [2:12], ...) to retain information.\n",
    "# Unable to implement stateful, so try to retain as much information between subsequences as possible. \n",
    "# Also a way of dataset augmentation (regularization) by increasing the size of the dataset\n",
    "\n",
    "def transpose_and_label_more(dataset_names, datasets, num_keys):\n",
    "    zs = []\n",
    "    datasets_transposed = np.array([(datasets[i].T, dataset_names[i]) for i in range(len(datasets))])\n",
    "    for song, composer in datasets_transposed:\n",
    "        for offset in range(0, sequence_length, 5):\n",
    "            for i in range(0, len(song)//sequence_length-offset):\n",
    "                x = song[offset+i*sequence_length:offset+(i+1)*sequence_length]\n",
    "                if i == len(song)//sequence_length - (1+offset): # Add the EOF marker if last seq of song\n",
    "                    y = np.append(song[offset+i*sequence_length+1:offset+(i+1)*sequence_length], np.array([np.ones(num_keys)]), 0)\n",
    "                else:\n",
    "                    y = song[offset+i*sequence_length+1:offset+(i+1)*sequence_length+1]\n",
    "                zs.append((x, y, composer))\n",
    "    np.random.shuffle(zs)\n",
    "    xs, ys, composers = [], [], []\n",
    "    for x, y, composer in zs:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        composers.append(composer)\n",
    "    return np.array(xs), np.array(ys), np.array(composers)\n",
    "\n",
    "train_xs, train_ys, train_composers = transpose_and_label_more(dataset_names, datasets, num_keys)\n",
    "test_xs = train_xs[int(len(train_xs)*0.8):]\n",
    "train_xs = train_xs[:int(len(train_xs)*0.8)]\n",
    "test_ys = train_ys[int(len(train_ys)*0.8):]\n",
    "train_ys = train_ys[:int(len(train_ys)*0.8)]\n",
    "test_composers = train_composers[int(len(train_composers)*0.8):]\n",
    "train_composers = train_composers[:int(len(train_composers)*0.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specialist_input = Input(shape=(composer_encoding_len,))\n",
    "x = Dense(16)(specialist_input) # Change the activation function within as the sigmoid quickly saturates due to shape. It's ok as output though.\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "specialist_output_c = Dense(num_keys, activation=\"relu\")(x)\n",
    "specialist_output_h = Dense(num_keys, activation=\"relu\")(x)\n",
    "#zero_input = Dropout(1)(specialist_output) # Hax to privde 0 as initial h.\n",
    "\n",
    "inputs = Input(shape=(sequence_length, num_keys))\n",
    "\n",
    "# Units = units per timestep LSTM block, i.e. output dimensionality (128 here since input and output 128 keys)\n",
    "lstm1 = LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True,\n",
    "               name=\"lstm1\")\n",
    "lstm1_outputs = lstm1(inputs, initial_state=[specialist_output_h, specialist_output_c]) # [h = prev output, c = memory], h should be None\n",
    "\n",
    "normalized1 = BatchNormalization()(lstm1_outputs)\n",
    "dense1 = Dense(num_keys, activation=\"relu\")(normalized1)\n",
    "\n",
    "lstm2 = LSTM(num_keys,\n",
    "               activation='relu',\n",
    "               return_sequences=True)(dense1)\n",
    "\n",
    "normalized2 = BatchNormalization()(lstm2)\n",
    "outputs = Dense(num_keys, activation=\"sigmoid\")(normalized2) # Sigmoid keeps the probabilities independent of each other, while softmax does not!\n",
    "\n",
    "model = Model([inputs, specialist_input], outputs)\n",
    "\n",
    "adam = Adam(lr=0.001, amsgrad=True) \n",
    "# Ends up in a point where gradients really small, denominator really small and then loss exploding\n",
    "# v_t is based on the gradients at the current time step, and previous v_t, thus when gradient really small as well as v_t-1\n",
    "# the update denominator (sqrt(v_t) + epsilon) is so small that explodes.\n",
    "# AMSGrad maintains the maximum of all v_t until the present time step and uses this maximum value for normalizing\n",
    "# the running average of the gradient instead of the current v_t as is done in regular Adam.\n",
    "\n",
    "#model.save(\"./models/latest.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          2176        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          2176        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 40, 128)      131584      input_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 40, 128)      512         lstm1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 40, 128)      16512       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 40, 128)      131584      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 40, 128)      512         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 40, 128)      16512       batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 301,712\n",
      "Trainable params: 301,168\n",
      "Non-trainable params: 544\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(6488, 40, 128) (6488, 4) (6488, 40, 128)\n",
      "Train on 6488 samples, validate on 1623 samples\n",
      "Epoch 1/250\n",
      "6488/6488 [==============================] - 39s 6ms/step - loss: 0.3407 - categorical_accuracy: 0.0616 - val_loss: 0.0857 - val_categorical_accuracy: 0.1075\n",
      "Epoch 2/250\n",
      "6488/6488 [==============================] - 47s 7ms/step - loss: 0.0725 - categorical_accuracy: 0.1318 - val_loss: 0.0663 - val_categorical_accuracy: 0.1453\n",
      "Epoch 3/250\n",
      "6488/6488 [==============================] - 42s 6ms/step - loss: 0.0608 - categorical_accuracy: 0.1626 - val_loss: 0.0594 - val_categorical_accuracy: 0.1729\n",
      "Epoch 4/250\n",
      "6144/6488 [===========================>..] - ETA: 1s - loss: 0.0563 - categorical_accuracy: 0.1800"
     ]
    }
   ],
   "source": [
    "# Want to penalize each output node independantly. \n",
    "# Log Loss aka multi-class multi-label as sigmoid -> binary CE, as want probs to be considered independent of each other.\n",
    "# Combo of sigmoid and crossentropy here log counteracts exp to reduce the saturation :)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, # consider changing this one for others\n",
    "              metrics=['categorical_accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(time()))\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5, verbose=0, mode=\"auto\")\n",
    "\n",
    "print(train_xs.shape, train_composers.shape, train_ys.shape)\n",
    "model.fit([train_xs, train_composers], train_ys,\n",
    "          epochs=250, # Train harder more for more things was too bad train man :(\n",
    "          batch_size=32,\n",
    "          shuffle=True, # shuffle here but not when constructing set to be able to validate later on :)\n",
    "          callbacks=[tensorboard, early_stop],\n",
    "          validation_data=([test_xs, test_composers], test_ys),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/nostate_40_offset_5_specialist.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model.predict([train_xs, train_composers], verbose=True)\n",
    "maxes = [np.max(c) for c in a]\n",
    "plt.hist(maxes)\n",
    "plt.show()\n",
    "plt.hist(a[:,-1])\n",
    "plt.show()\n",
    "b = np.max(a[1][-1])\n",
    "plt.plot(a[1][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[0].T, fs=5)\n",
    "prep.visualize_piano_roll(train_xs[0].T, fs=5)\n",
    "plt.plot(a[100][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[100].T, fs=5)\n",
    "prep.visualize_piano_roll(train_xs[100].T, fs=5)\n",
    "plt.plot(a[200][-1])\n",
    "plt.show()\n",
    "prep.visualize_piano_roll(a[200].T, fs=5)\n",
    "prep.visualize_piano_roll(train_xs[200].T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_song_from_predict(model, initial_data, composer, limit):\n",
    "    song = []\n",
    "    keep_producing = True\n",
    "    prev_data = initial_data\n",
    "    while keep_producing and len(song) < limit:\n",
    "        predictions = model.predict([np.array([prev_data]), composer])[0]\n",
    "        labels = np.zeros(128)\n",
    "        labels[predictions[-1]/np.max(predictions[-1])>0.5] = 1 # Threshold to consider the key as active, binarized based on this\n",
    "        last_output = labels[-1]\n",
    "        keep_producing = np.sum(last_output) != len(last_output)\n",
    "        song.append(last_output)\n",
    "        prev_data = np.append(prev_data[1:], [last_output], 0)\n",
    "    return np.array(song)\n",
    "\n",
    "initial_step = 250\n",
    "steps = 10\n",
    "song1 = make_song_from_predict(model, train_xs[initial_step], np.array([[1.0, 0.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song2 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 1.0, 0.0, 0.0]]), sequence_length*steps)\n",
    "song3 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 1.0, 0.0]]), sequence_length*steps)\n",
    "song4 = make_song_from_predict(model, train_xs[initial_step], np.array([[0.0, 0.0, 0.0, 1.0]]), sequence_length*steps)\n",
    "prep.embed_play_v1(song1.T, fs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song2.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song3.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.embed_play_v1(song4.T, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual = train_xs[initial_step+1]\n",
    "print(train_composers[initial_step])\n",
    "print(int_to_name[list(train_composers[initial_step]).index(1)])\n",
    "for i in range(1, steps):\n",
    "    actual = np.append(actual, train_xs[initial_step+1+i], axis=0)\n",
    "actual = actual.T\n",
    "prep.visualize_piano_roll(song1.T, fs=5)\n",
    "prep.visualize_piano_roll(song2.T, fs=5)\n",
    "prep.visualize_piano_roll(song3.T, fs=5)\n",
    "prep.visualize_piano_roll(song4.T, fs=5)\n",
    "prep.visualize_piano_roll(actual, fs=5)\n",
    "prep.embed_play_v1(actual, fs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = load_model(\"./models/nostate_40_offset_5_specialist.h5f\")\n",
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "print(model.summary())\n",
    "a = model.evaluate([train_xs, train_composers], train_ys,\n",
    "          batch_size=32)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
